{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2748e40c",
   "metadata": {},
   "source": [
    "Regression for predicting the price of the house"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1742a",
   "metadata": {},
   "source": [
    "# Steps we will follow:\n",
    "\n",
    "## 1. Define the objective\n",
    "- defining the target \n",
    "- defining a acceptable error (we will take into account MAE for the error) â†’ **So define Maximum MAE**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Select data for the model\n",
    "- cleaning of that data (en principio no va a hacer falta)\n",
    "- Detectar outliers que puedan romper el modelo\n",
    "\n",
    "---\n",
    "\n",
    "## 3. EDA para detectar si un linear regression va a ser suficiente: justificarlo y aplicar un linear regression para demostrarlo\n",
    "\n",
    "### 3.1 Univariado\n",
    "- DistribuciÃ³n del target.\n",
    "- DistribuciÃ³n y estadÃ­sticas de las features.\n",
    "\n",
    "### 3.2 Bivariado\n",
    "- Correlaciones numÃ©ricas (heatmap).\n",
    "- ANOVA / boxplots para categÃ³ricas vs target.\n",
    "\n",
    "### 3.3 Detectar no linealidades\n",
    "- Scatterplots X vs Y.\n",
    "- Transformaciones (log, sqrt) si una relaciÃ³n no es lineal.\n",
    "- Crear polinÃ³micas si es necesario.\n",
    "\n",
    "> ðŸ‘‰ AquÃ­ decides si la regresiÃ³n lineal tiene sentido o necesitas algo mÃ¡s poderoso.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ”ï¸ Â¿CÃ³mo elegir definitivamente?\n",
    "Se hace asÃ­:\n",
    "\n",
    "1ï¸âƒ£ Divide los datos (train/test)  \n",
    "2ï¸âƒ£ Ejecuta cross-validation con GridSearch:  \n",
    "\n",
    "- Lasso  \n",
    "- Ridge  \n",
    "- ElasticNet  \n",
    "\n",
    "El que dÃ© mejor MAE o RMSE â†’ ese gana.  \n",
    "\n",
    "âž¡ï¸ No se decide a ojo. Se decide con CV.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Validar Supuestos: (aplicar lasso directamente y verificar)\n",
    "- Linealidad\n",
    "- Independencia de residuos\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Preprocesing\n",
    "- Dividir train y test\n",
    "- Scaled, categorical-variables...\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Entrenar y probar con varios modelos (usando cross validation)\n",
    "\n",
    "### Entrenar y probar con:\n",
    "- âœ”ï¸ RANSAC  \n",
    "  Para outliers, recomendado\n",
    "\n",
    "- âœ”ï¸ Theil-Sen  \n",
    "  Robusto a ruido, muy usado en datos inestables\n",
    "\n",
    "- âœ”ï¸ HuberRegressor  \n",
    "  Mezcla LR con robustez\n",
    "\n",
    "- âœ”ï¸ RandomForestRegressor  \n",
    "  No lineal, buen baseline potente\n",
    "\n",
    "- âœ”ï¸ CatBoost  \n",
    "  De lo mejor en tabular  \n",
    "  No requiere escalado  \n",
    "  Maneja categÃ³ricas\n",
    "\n",
    "- âœ”ï¸ XGBoost\n",
    "\n",
    "- âœ”ï¸ LightGBM  \n",
    "\n",
    "Casi siempre da un rendimiento brutal\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluar mÃ©tricas\n",
    "- RÂ², MAE\n",
    "- Comprobar si hay overfitting o underfitting en cada modelo:  \n",
    "    - Overfitting â†’ test mucho peor que train  \n",
    "    - Underfitting â†’ ambos malos  \n",
    "    - Buen modelo â†’ train â‰ˆ test y mÃ©tricas buenas  \n",
    "\n",
    "> ðŸ‘‰ El test manda; si test es bueno â†’ el modelo generaliza.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. DiagnÃ³stico final (para verificar si el modelo que hemos elegido esta bien)\n",
    "- Residuals vs predicted\n",
    "- Predicted vs actual\n",
    "- Q-Q plot\n",
    "- Importancia de variables\n",
    "- Coeficientes interpretables (si es lineal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d660c",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cec17d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26cc48",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ebe488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "\n",
    "data = pd.read_csv('../data/cleaned/data_final.csv')\n",
    "dataCpy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3d38b",
   "metadata": {},
   "source": [
    "### 1: Define the objective of the regression: \n",
    "- Target feature: price\n",
    "- Now we will justify which will, what we will consider an acceptable maximum MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c673265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of the feature 'price': 310649.51â‚¬\n"
     ]
    }
   ],
   "source": [
    "#Since the target feature is the price, the MAE will be in â‚¬ units.\n",
    "\n",
    "#AN OPTION WOULD BE: \n",
    "\n",
    "#1.We will get which is the standard deviation of \"price\" feature \n",
    "std_price = dataCpy[\"price\"].std()\n",
    "print(f\"Standard deviation of the feature 'price': {round(std_price,2)}â‚¬\") #--> The values of \"price\" differ from the mean: 310649.51â‚¬\n",
    "\n",
    "#2.The maximum accepatble MAE could be a percentage of that standard deviation value. \n",
    "#In the house business, 31.000â‚¬ more or less expensive may have an impact on buyers, however a price of 10.000â‚¬ may not have so much impact. \n",
    "#So an acceptale MAE will be 10.000â‚¬ for all the predictions. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c93c2",
   "metadata": {},
   "source": [
    "HOWEVER: \n",
    "\n",
    "The first option would be easier to implement (1 fixed maximum MAE for all the predictions). However, this would not be true. \n",
    "Since 10.000â‚¬ may not have an impact (would be an acecptable MAE) for a house of 500.000â‚¬ for example, but would have a big \n",
    "impact (would NOT be an acceptable MAE) for a house of 50.000â‚¬.\n",
    "\n",
    "So we will take into account the \"relative MAE\" with an error of 5%. So for example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bef786fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheapest House: 50000.0â‚¬\n",
      "5% = 2500.0â‚¬\n",
      "\n",
      "Most Expensive House: 2500000.0â‚¬\n",
      "5% = 125000.0â‚¬\n",
      "\n",
      "Average price House: 477005.01â‚¬\n",
      "5% = 23850.25â‚¬\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Cheapest House: {round(min(dataCpy[\"price\"]),2)}â‚¬\")\n",
    "print(f\"5% = {round(min(dataCpy[\"price\"])*0.05,2)}â‚¬\\n\")\n",
    "\n",
    "print(f\"Most Expensive House: {round(max(dataCpy[\"price\"]),2)}â‚¬\")\n",
    "print(f\"5% = {round(max(dataCpy[\"price\"])*0.05,2)}â‚¬\\n\")\n",
    "\n",
    "print(f\"Average price House: {round(st.mean(dataCpy[\"price\"]),2)}â‚¬\")\n",
    "print(f\"5% = {round(st.mean(dataCpy[\"price\"])*0.05,2)}â‚¬\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae04b54",
   "metadata": {},
   "source": [
    "### 2: Data cleaning for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0163edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "url                  0\n",
      "price                0\n",
      "zone                 0\n",
      "neighborhood         0\n",
      "built_area           0\n",
      "usable_area          0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "floor                0\n",
      "exterior             0\n",
      "elevator             0\n",
      "garage               0\n",
      "storage_room         0\n",
      "balcony              0\n",
      "new                  0\n",
      "condition            0\n",
      "year                 0\n",
      "agency               0\n",
      "consumption_label    0\n",
      "emissions_label      0\n",
      "description          8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.We will check if there are missing values (there should not be any, since we have previously done data cleaning)\n",
    "print(f\"Missing values:\\n{dataCpy.isnull().sum()}\") #0 missing values in target and the other features PERFECT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a80b4619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: Index(['url', 'price', 'zone', 'neighborhood', 'built_area', 'usable_area',\n",
      "       'bedrooms', 'bathrooms', 'floor', 'exterior', 'elevator', 'garage',\n",
      "       'storage_room', 'balcony', 'new', 'condition', 'year', 'agency',\n",
      "       'consumption_label', 'emissions_label', 'description'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Initially selected features: Index(['zone', 'neighborhood', 'built_area', 'usable_area', 'bedrooms',\n",
      "       'bathrooms', 'floor', 'exterior', 'elevator', 'garage', 'storage_room',\n",
      "       'balcony', 'new', 'condition', 'year', 'agency', 'consumption_label',\n",
      "       'emissions_label', 'description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#2.We will get the features which the model will be working with (initally)\n",
    "\n",
    "print(f\"All features: {dataCpy.columns}\\n\\n\")\n",
    "\n",
    "#We will not take into account: Url and price (is the target) \n",
    "\n",
    "target_price = dataCpy.price\n",
    "data_regresion = dataCpy.drop([\"url\",\"price\"], axis=1)\n",
    "print(f\"Initially selected features: {data_regresion.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb50c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.We will check if there are any outliers in the values of \"price\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
