{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccab467",
   "metadata": {},
   "source": [
    "# **CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b060278",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db1d9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bascic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Model imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# More robust model imports\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1778d1",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e046928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1230 entries, 0 to 1229\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   price              1230 non-null   float64 \n",
      " 1   zone               1230 non-null   category\n",
      " 2   neighborhood       1230 non-null   category\n",
      " 3   built_area         1230 non-null   float64 \n",
      " 4   usable_area        1230 non-null   float64 \n",
      " 5   bedrooms           1230 non-null   int64   \n",
      " 6   bathrooms          1230 non-null   int64   \n",
      " 7   floor              1230 non-null   float64 \n",
      " 8   exterior           1230 non-null   category\n",
      " 9   elevator           1230 non-null   bool    \n",
      " 10  garage             1230 non-null   bool    \n",
      " 11  storage_room       1230 non-null   bool    \n",
      " 12  balcony            1230 non-null   bool    \n",
      " 13  new                1230 non-null   bool    \n",
      " 14  condition          1230 non-null   category\n",
      " 15  year               1230 non-null   float64 \n",
      " 16  agency             1230 non-null   category\n",
      " 17  consumption_label  1230 non-null   category\n",
      " 18  emissions_label    1230 non-null   category\n",
      "dtypes: bool(5), category(7), float64(5), int64(2)\n",
      "memory usage: 97.2 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/cleaned/data_final.csv')\n",
    "\n",
    "# We drop the columns that we won't use for classification\n",
    "data = data.drop(columns=[\"url\", \"description\"])\n",
    "\n",
    "# Convertimos las columnas de texto a categorías\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# data.info()\n",
    "# data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc9213",
   "metadata": {},
   "source": [
    "## Based on Zone\n",
    "\n",
    "First we will try to classify the houses according to their zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e0aaf",
   "metadata": {},
   "source": [
    "### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6affda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the neighbourhood column to classify by zone\n",
    "data_zone = data.drop(columns=[\"neighborhood\"])\n",
    "\n",
    "# We also split the data into features and target\n",
    "X_zone = data_zone.drop(columns=[\"zone\"])\n",
    "y_zone = data_zone[\"zone\"]\n",
    "\n",
    "# Check everything is ok\n",
    "#print(y_zone.head())\n",
    "#X_zone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b953769",
   "metadata": {},
   "source": [
    "### Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e68785a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para evaluación (ajustadas para clasificación multiclase)\n",
    "SCORING = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall_weighted': 'recall_weighted',\n",
    "    'precision_weighted': 'precision_weighted',\n",
    "    'f1_weighted': 'f1_weighted',\n",
    "    'matthews': \"matthews_corrcoef\",\n",
    "    'balanced_accuracy': 'balanced_accuracy'\n",
    "}\n",
    "\n",
    "# Probar múltiples modelos\n",
    "MODELS = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Random Forest (tuned)': RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "#    'SVM (Linear)': SVC(kernel='linear', random_state=42, probability=True),\n",
    "#    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Hist Gradient Boosting': HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0) # (Verbose=0 para que no llene la pantalla de logs)\n",
    "}\n",
    "\n",
    "# Usar StratifiedKFold para mantener la distribución de clases\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfbd8f",
   "metadata": {},
   "source": [
    "### Defining function to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c17fe8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, cv_strategy=cv_strategy, scoring=SCORING, models=MODELS):\n",
    "    # We are going to try all defined models\n",
    "    results = {}\n",
    "    # We evaluate each model using cross-validation\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        scores = cross_validate(model, X, y, cv=cv_strategy, scoring=scoring, return_train_score=False, n_jobs=-1)\n",
    "        \n",
    "        # We check the results with several metrics\n",
    "        results[name] = {}\n",
    "        for metric_name, metric_scores in scores.items():\n",
    "            if metric_name.startswith('test_'):\n",
    "                metric = metric_name.replace('test_', '')\n",
    "                results[name][metric] = (metric_scores.mean(), metric_scores.std())\n",
    "                print(f\"  {metric}: {metric_scores.mean():.4f} (+/- {metric_scores.std():.4f})\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb003bb",
   "metadata": {},
   "source": [
    "### Strategy 1\n",
    "Use all the variables, encoding categorical ones as dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da5a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 324\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "Random Forest:\n",
      "  accuracy: 0.6073 (+/- 0.0225)\n",
      "  recall_weighted: 0.6073 (+/- 0.0225)\n",
      "  precision_weighted: 0.6346 (+/- 0.0297)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5531 (+/- 0.0262)\n",
      "  balanced_accuracy: 0.5439 (+/- 0.0370)\n",
      "\n",
      "Random Forest (tuned):\n",
      "  accuracy: 0.5707 (+/- 0.0186)\n",
      "  recall_weighted: 0.5707 (+/- 0.0186)\n",
      "  precision_weighted: 0.6337 (+/- 0.0337)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5133 (+/- 0.0213)\n",
      "  balanced_accuracy: 0.4814 (+/- 0.0293)\n",
      "\n",
      "Logistic Regression:\n",
      "  accuracy: 0.2976 (+/- 0.0167)\n",
      "  recall_weighted: 0.2976 (+/- 0.0167)\n",
      "  precision_weighted: 0.1599 (+/- 0.0158)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.1862 (+/- 0.0223)\n",
      "  balanced_accuracy: 0.1768 (+/- 0.0092)\n",
      "\n",
      "Naive Bayes:\n",
      "  accuracy: 0.3317 (+/- 0.0208)\n",
      "  recall_weighted: 0.3317 (+/- 0.0208)\n",
      "  precision_weighted: 0.3318 (+/- 0.0481)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.2463 (+/- 0.0258)\n",
      "  balanced_accuracy: 0.2459 (+/- 0.0209)\n",
      "\n",
      "Gradient Boosting:\n",
      "  accuracy: 0.5789 (+/- 0.0285)\n",
      "  recall_weighted: 0.5789 (+/- 0.0285)\n",
      "  precision_weighted: 0.5960 (+/- 0.0346)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5218 (+/- 0.0325)\n",
      "  balanced_accuracy: 0.5240 (+/- 0.0398)\n",
      "\n",
      "Hist Gradient Boosting:\n",
      "  accuracy: 0.6439 (+/- 0.0179)\n",
      "  recall_weighted: 0.6439 (+/- 0.0179)\n",
      "  precision_weighted: 0.6500 (+/- 0.0162)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5965 (+/- 0.0200)\n",
      "  balanced_accuracy: 0.6118 (+/- 0.0234)\n",
      "\n",
      "XGBoost:\n",
      "  accuracy: 0.6634 (+/- 0.0104)\n",
      "  recall_weighted: 0.6634 (+/- 0.0104)\n",
      "  precision_weighted: 0.6713 (+/- 0.0135)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.6187 (+/- 0.0116)\n",
      "  balanced_accuracy: 0.6436 (+/- 0.0097)\n",
      "\n",
      "LightGBM:\n",
      "  accuracy: 0.6268 (+/- 0.0214)\n",
      "  recall_weighted: 0.6268 (+/- 0.0214)\n",
      "  precision_weighted: 0.6378 (+/- 0.0190)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5772 (+/- 0.0237)\n",
      "  balanced_accuracy: 0.5892 (+/- 0.0228)\n",
      "\n",
      "CatBoost:\n",
      "  accuracy: 0.6049 (+/- 0.0107)\n",
      "  recall_weighted: 0.6049 (+/- 0.0107)\n",
      "  precision_weighted: 0.6155 (+/- 0.0101)\n",
      "  f1_weighted: nan (+/- nan)\n",
      "  matthews: 0.5514 (+/- 0.0122)\n",
      "  balanced_accuracy: 0.5679 (+/- 0.0195)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ESTRATEGIA 1:\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cat_cols1 = [\"exterior\", \"condition\", \"agency\", \"consumption_label\", \"emissions_label\"]\n",
    "\n",
    "X_zone_encoded_1 = pd.get_dummies(X_zone, columns=cat_cols1)\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_encoded_1.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_encoded_1.columns]\n",
    "y_zone_encoded_1 = LabelEncoder().fit_transform(y_zone)\n",
    "\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_encoded_1)}\")\n",
    "print(f\"Número de features: {X_zone_encoded_1.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_encoded_1)}\")\n",
    "\n",
    "result1s = evaluate_models(X_zone_encoded_1, y_zone_encoded_1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2acf1f9",
   "metadata": {},
   "source": [
    "### Strategy 1.1\n",
    "We have seen that some models handle categorical columns automatically (without having to use the dummies), which can improve both the time required to fit the model and the result, so we will try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a07500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models that handle categorical features natively\n",
    "\n",
    "# Probar múltiples modelos\n",
    "MODELS_NATIVE = {\n",
    "    'Hist Gradient Boosting': HistGradientBoostingClassifier(max_iter=100, random_state=42, \n",
    "    categorical_features='from_dtype' # <--- Clave: lee el tipo 'category' de Pandas\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=100, \n",
    "        learning_rate=0.1, \n",
    "        random_state=42, \n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\",      # <--- Necesario para el modo rápido\n",
    "        enable_categorical=True, # <--- Activa el soporte nativo\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42, \n",
    "        n_jobs=-1, \n",
    "        verbose=-1 # Silenciar warnings\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=100, \n",
    "        random_state=42, \n",
    "        verbose=0,                # Silencioso\n",
    "        allow_writing_files=False # Evita crear carpetas 'catboost_info'\n",
    "    )\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
