{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccab467",
   "metadata": {},
   "source": [
    "# **CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b060278",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db1d9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bascic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Model imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# More robust model imports\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1778d1",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e046928",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/cleaned/data_final.csv')\n",
    "\n",
    "# We drop the columns that we won't use for classification\n",
    "data = data.drop(columns=[\"url\", \"description\"])\n",
    "\n",
    "# Convertimos las columnas de texto a categorías\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# data.info()\n",
    "# data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc9213",
   "metadata": {},
   "source": [
    "## Based on Zone\n",
    "\n",
    "First we will try to classify the houses according to their zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e0aaf",
   "metadata": {},
   "source": [
    "### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6affda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the neighbourhood column to classify by zone\n",
    "data_zone = data.drop(columns=[\"neighborhood\"])\n",
    "\n",
    "# We also split the data into features and target\n",
    "X_zone = data_zone.drop(columns=[\"zone\"])\n",
    "y_zone = data_zone[\"zone\"]\n",
    "\n",
    "# Check everything is ok\n",
    "#print(y_zone.head())\n",
    "#X_zone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b953769",
   "metadata": {},
   "source": [
    "### Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e68785a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para evaluación (ajustadas para clasificación multiclase)\n",
    "SCORING = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall_weighted': 'recall_weighted',\n",
    "    'precision_weighted': 'precision_weighted',\n",
    "    'f1_weighted': 'f1_weighted',\n",
    "    'f1_macro': 'f1_macro',       # CRÍTICO: Te dirá si estás fallando en las clases pequeñas\n",
    "    'matthews': \"matthews_corrcoef\",\n",
    "    'balanced_accuracy': 'balanced_accuracy'\n",
    "}\n",
    "\n",
    "# Probar múltiples modelos\n",
    "MODELS = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Random Forest (tuned)': RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "#    'SVM (Linear)': SVC(kernel='linear', random_state=42, probability=True),\n",
    "#    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Hist Gradient Boosting': HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0, allow_writing_files=False), # (Verbose=0 para que no llene la pantalla de logs)\n",
    "    'Neural Network (MLP)': make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))\n",
    "}\n",
    "\n",
    "# Usar StratifiedKFold para mantener la distribución de clases\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfbd8f",
   "metadata": {},
   "source": [
    "### Defining function to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c17fe8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, cv_strategy=cv_strategy, scoring=SCORING, models=MODELS):\n",
    "    # We are going to try all defined models\n",
    "    results = {}\n",
    "    # We evaluate each model using cross-validation\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        scores = cross_validate(model, X, y, cv=cv_strategy, scoring=scoring, return_train_score=False, n_jobs=-1)\n",
    "        \n",
    "        # We check the results with several metrics\n",
    "        results[name] = {}\n",
    "        for metric_name, metric_scores in scores.items():\n",
    "            if metric_name.startswith('test_'):\n",
    "                metric = metric_name.replace('test_', '')\n",
    "                results[name][metric] = (metric_scores.mean(), metric_scores.std())\n",
    "                print(f\"  {metric}: {metric_scores.mean():.4f} (+/- {metric_scores.std():.4f})\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb003bb",
   "metadata": {},
   "source": [
    "### Strategy 1\n",
    "Use all the variables, encoding categorical ones as dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da5a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 324\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "Random Forest:\n",
      "  accuracy: 0.6073 (+/- 0.0225)\n",
      "  recall_weighted: 0.6073 (+/- 0.0225)\n",
      "  precision_weighted: 0.6346 (+/- 0.0297)\n",
      "  f1_weighted: 0.5966 (+/- 0.0253)\n",
      "  f1_macro: 0.5697 (+/- 0.0380)\n",
      "  matthews: 0.5531 (+/- 0.0262)\n",
      "  balanced_accuracy: 0.5439 (+/- 0.0370)\n",
      "\n",
      "Random Forest (tuned):\n",
      "  accuracy: 0.5707 (+/- 0.0186)\n",
      "  recall_weighted: 0.5707 (+/- 0.0186)\n",
      "  precision_weighted: 0.6337 (+/- 0.0337)\n",
      "  f1_weighted: 0.5493 (+/- 0.0209)\n",
      "  f1_macro: 0.5133 (+/- 0.0309)\n",
      "  matthews: 0.5133 (+/- 0.0213)\n",
      "  balanced_accuracy: 0.4814 (+/- 0.0293)\n",
      "\n",
      "Logistic Regression:\n",
      "  accuracy: 0.2976 (+/- 0.0167)\n",
      "  recall_weighted: 0.2976 (+/- 0.0167)\n",
      "  precision_weighted: 0.1599 (+/- 0.0158)\n",
      "  f1_weighted: 0.1957 (+/- 0.0071)\n",
      "  f1_macro: 0.1168 (+/- 0.0055)\n",
      "  matthews: 0.1862 (+/- 0.0223)\n",
      "  balanced_accuracy: 0.1768 (+/- 0.0092)\n",
      "\n",
      "Naive Bayes:\n",
      "  accuracy: 0.3317 (+/- 0.0208)\n",
      "  recall_weighted: 0.3317 (+/- 0.0208)\n",
      "  precision_weighted: 0.3318 (+/- 0.0481)\n",
      "  f1_weighted: 0.2834 (+/- 0.0243)\n",
      "  f1_macro: 0.2123 (+/- 0.0198)\n",
      "  matthews: 0.2463 (+/- 0.0258)\n",
      "  balanced_accuracy: 0.2459 (+/- 0.0209)\n",
      "\n",
      "Gradient Boosting:\n",
      "  accuracy: 0.5789 (+/- 0.0285)\n",
      "  recall_weighted: 0.5789 (+/- 0.0285)\n",
      "  precision_weighted: 0.5960 (+/- 0.0346)\n",
      "  f1_weighted: 0.5713 (+/- 0.0289)\n",
      "  f1_macro: 0.5425 (+/- 0.0405)\n",
      "  matthews: 0.5218 (+/- 0.0325)\n",
      "  balanced_accuracy: 0.5240 (+/- 0.0398)\n",
      "\n",
      "Hist Gradient Boosting:\n",
      "  accuracy: 0.6439 (+/- 0.0179)\n",
      "  recall_weighted: 0.6439 (+/- 0.0179)\n",
      "  precision_weighted: 0.6500 (+/- 0.0162)\n",
      "  f1_weighted: 0.6425 (+/- 0.0177)\n",
      "  f1_macro: 0.6253 (+/- 0.0222)\n",
      "  matthews: 0.5965 (+/- 0.0200)\n",
      "  balanced_accuracy: 0.6118 (+/- 0.0234)\n",
      "\n",
      "XGBoost:\n",
      "  accuracy: 0.6634 (+/- 0.0104)\n",
      "  recall_weighted: 0.6634 (+/- 0.0104)\n",
      "  precision_weighted: 0.6713 (+/- 0.0135)\n",
      "  f1_weighted: 0.6630 (+/- 0.0112)\n",
      "  f1_macro: 0.6572 (+/- 0.0121)\n",
      "  matthews: 0.6187 (+/- 0.0116)\n",
      "  balanced_accuracy: 0.6436 (+/- 0.0097)\n",
      "\n",
      "LightGBM:\n",
      "  accuracy: 0.6268 (+/- 0.0214)\n",
      "  recall_weighted: 0.6268 (+/- 0.0214)\n",
      "  precision_weighted: 0.6378 (+/- 0.0190)\n",
      "  f1_weighted: 0.6244 (+/- 0.0191)\n",
      "  f1_macro: 0.6030 (+/- 0.0197)\n",
      "  matthews: 0.5772 (+/- 0.0237)\n",
      "  balanced_accuracy: 0.5892 (+/- 0.0228)\n",
      "\n",
      "CatBoost:\n",
      "  accuracy: 0.6049 (+/- 0.0107)\n",
      "  recall_weighted: 0.6049 (+/- 0.0107)\n",
      "  precision_weighted: 0.6155 (+/- 0.0101)\n",
      "  f1_weighted: 0.6002 (+/- 0.0118)\n",
      "  f1_macro: 0.5834 (+/- 0.0215)\n",
      "  matthews: 0.5514 (+/- 0.0122)\n",
      "  balanced_accuracy: 0.5679 (+/- 0.0195)\n",
      "\n",
      "Neural Network (MLP):\n",
      "  accuracy: 0.4211 (+/- 0.0203)\n",
      "  recall_weighted: 0.4211 (+/- 0.0203)\n",
      "  precision_weighted: 0.4186 (+/- 0.0265)\n",
      "  f1_weighted: 0.4162 (+/- 0.0216)\n",
      "  f1_macro: 0.3704 (+/- 0.0384)\n",
      "  matthews: 0.3441 (+/- 0.0238)\n",
      "  balanced_accuracy: 0.3737 (+/- 0.0421)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ESTRATEGIA 1:\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cat_cols1 = [\"exterior\", \"condition\", \"agency\", \"consumption_label\", \"emissions_label\"]\n",
    "\n",
    "X_zone_encoded_1 = pd.get_dummies(X_zone, columns=cat_cols1)\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_encoded_1.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_encoded_1.columns]\n",
    "y_zone_encoded_1 = LabelEncoder().fit_transform(y_zone)\n",
    "\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_encoded_1)}\")\n",
    "print(f\"Número de features: {X_zone_encoded_1.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_encoded_1)}\")\n",
    "\n",
    "result1 = evaluate_models(X_zone_encoded_1, y_zone_encoded_1, models=MODELS, cv_strategy=cv_strategy)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2acf1f9",
   "metadata": {},
   "source": [
    "### Strategy 1.1\n",
    "We have seen that some models handle categorical columns automatically (without having to use the dummies), which can improve both the time required to fit the model and the result, so we will try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2a07500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1.1: Utilizar todas las variables, manteniendo categóricas como categorías (modelos que lo soportan)\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 17\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "XGBoost:\n",
      "  accuracy: 0.6285 (+/- 0.0211)\n",
      "  recall_weighted: 0.6285 (+/- 0.0211)\n",
      "  precision_weighted: 0.6354 (+/- 0.0232)\n",
      "  f1_weighted: 0.6253 (+/- 0.0221)\n",
      "  f1_macro: 0.6213 (+/- 0.0228)\n",
      "  matthews: 0.5792 (+/- 0.0242)\n",
      "  balanced_accuracy: 0.6127 (+/- 0.0271)\n",
      "\n",
      "LightGBM:\n",
      "  accuracy: 0.6699 (+/- 0.0151)\n",
      "  recall_weighted: 0.6699 (+/- 0.0151)\n",
      "  precision_weighted: 0.6793 (+/- 0.0130)\n",
      "  f1_weighted: 0.6680 (+/- 0.0145)\n",
      "  f1_macro: 0.6538 (+/- 0.0222)\n",
      "  matthews: 0.6260 (+/- 0.0169)\n",
      "  balanced_accuracy: 0.6401 (+/- 0.0238)\n",
      "\n",
      "CatBoost:\n",
      "  accuracy: 0.5764 (+/- 0.0181)\n",
      "  recall_weighted: 0.5764 (+/- 0.0181)\n",
      "  precision_weighted: 0.5914 (+/- 0.0205)\n",
      "  f1_weighted: 0.5667 (+/- 0.0183)\n",
      "  f1_macro: 0.5343 (+/- 0.0277)\n",
      "  matthews: 0.5199 (+/- 0.0206)\n",
      "  balanced_accuracy: 0.5221 (+/- 0.0267)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Models that handle categorical features natively\n",
    "MODELS_NATIVE = {\n",
    "    'XGBoost': XGBClassifier( n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1, tree_method=\"hist\", # <--- Necesario para el modo rápido\n",
    "        enable_categorical=True, use_label_encoder=False, eval_metric='mlogloss'), # <--- Habilita manejo de categóricas\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0, allow_writing_files=False,\n",
    "        cat_features=cat_cols1), # Evita crear carpetas 'catboost_info'\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1.1: Utilizar todas las variables, manteniendo categóricas como categorías (modelos que lo soportan)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_zone_uncoded_1 = X_zone.copy()\n",
    "\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_uncoded_1.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_uncoded_1.columns]\n",
    "y_zone_unencoded_1 = LabelEncoder().fit_transform(y_zone)\n",
    "\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_uncoded_1)}\")\n",
    "print(f\"Número de features: {X_zone_uncoded_1.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_unencoded_1)}\")\n",
    "\n",
    "result11 = evaluate_models(X_zone_uncoded_1, y_zone_unencoded_1, models=MODELS_NATIVE, scoring=SCORING)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
