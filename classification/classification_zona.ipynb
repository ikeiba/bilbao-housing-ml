{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccab467",
   "metadata": {},
   "source": [
    "# **CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b060278",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db1d9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bascic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Model imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# More robust model imports\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1778d1",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e046928",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/cleaned/data_final.csv')\n",
    "\n",
    "# We drop the columns that we won't use for classification\n",
    "data = data.drop(columns=[\"url\", \"description\"])\n",
    "\n",
    "# Convertimos las columnas de texto a categorías\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category')\n",
    "\n",
    "# data.info()\n",
    "# data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc9213",
   "metadata": {},
   "source": [
    "## Based on Zone\n",
    "\n",
    "First we will try to classify the houses according to their zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e0aaf",
   "metadata": {},
   "source": [
    "### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6affda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the neighbourhood column to classify by zone\n",
    "data_zone = data.drop(columns=[\"neighborhood\"])\n",
    "\n",
    "# We also split the data into features and target\n",
    "X_zone = data_zone.drop(columns=[\"zone\"])\n",
    "y_zone = data_zone[\"zone\"]\n",
    "\n",
    "# Check everything is ok\n",
    "#print(y_zone.head())\n",
    "#X_zone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b953769",
   "metadata": {},
   "source": [
    "### Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e68785a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas para evaluación (ajustadas para clasificación multiclase)\n",
    "SCORING = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall_weighted': 'recall_weighted',\n",
    "    'precision_weighted': 'precision_weighted',\n",
    "    'f1_weighted': 'f1_weighted',\n",
    "    'f1_macro': 'f1_macro',       # CRÍTICO: Te dirá si estás fallando en las clases pequeñas\n",
    "    'matthews': \"matthews_corrcoef\",\n",
    "    'balanced_accuracy': 'balanced_accuracy'\n",
    "}\n",
    "\n",
    "# Probar múltiples modelos\n",
    "MODELS = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Random Forest (tuned)': RandomForestClassifier(n_estimators=300, max_depth=15, min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "#    'SVM (Linear)': SVC(kernel='linear', random_state=42, probability=True),\n",
    "#    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Hist Gradient Boosting': HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0, allow_writing_files=False), # (Verbose=0 para que no llene la pantalla de logs)\n",
    "    'Neural Network (MLP)': make_pipeline(StandardScaler(), MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42))\n",
    "}\n",
    "\n",
    "# Usar StratifiedKFold para mantener la distribución de clases\n",
    "cv_strategy = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfbd8f",
   "metadata": {},
   "source": [
    "### Defining function to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c17fe8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y, cv_strategy=cv_strategy, scoring=SCORING, models=MODELS):\n",
    "    # We are going to try all defined models\n",
    "    results = {}\n",
    "    # We evaluate each model using cross-validation\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        scores = cross_validate(model, X, y, cv=cv_strategy, scoring=scoring, return_train_score=False, n_jobs=-1)\n",
    "        \n",
    "        # We check the results with several metrics\n",
    "        results[name] = {}\n",
    "        for metric_name, metric_scores in scores.items():\n",
    "            if metric_name.startswith('test_'):\n",
    "                metric = metric_name.replace('test_', '')\n",
    "                results[name][metric] = (metric_scores.mean(), metric_scores.std())\n",
    "                print(f\"  {metric}: {metric_scores.mean():.4f} (+/- {metric_scores.std():.4f})\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb003bb",
   "metadata": {},
   "source": [
    "### Strategy 1\n",
    "Use all the variables, encoding categorical ones as dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da5a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 324\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "Random Forest:\n",
      "  accuracy: 0.6073 (+/- 0.0225)\n",
      "  recall_weighted: 0.6073 (+/- 0.0225)\n",
      "  precision_weighted: 0.6346 (+/- 0.0297)\n",
      "  f1_weighted: 0.5966 (+/- 0.0253)\n",
      "  f1_macro: 0.5697 (+/- 0.0380)\n",
      "  matthews: 0.5531 (+/- 0.0262)\n",
      "  balanced_accuracy: 0.5439 (+/- 0.0370)\n",
      "\n",
      "Random Forest (tuned):\n",
      "  accuracy: 0.5707 (+/- 0.0186)\n",
      "  recall_weighted: 0.5707 (+/- 0.0186)\n",
      "  precision_weighted: 0.6337 (+/- 0.0337)\n",
      "  f1_weighted: 0.5493 (+/- 0.0209)\n",
      "  f1_macro: 0.5133 (+/- 0.0309)\n",
      "  matthews: 0.5133 (+/- 0.0213)\n",
      "  balanced_accuracy: 0.4814 (+/- 0.0293)\n",
      "\n",
      "Logistic Regression:\n",
      "  accuracy: 0.2976 (+/- 0.0167)\n",
      "  recall_weighted: 0.2976 (+/- 0.0167)\n",
      "  precision_weighted: 0.1599 (+/- 0.0158)\n",
      "  f1_weighted: 0.1957 (+/- 0.0071)\n",
      "  f1_macro: 0.1168 (+/- 0.0055)\n",
      "  matthews: 0.1862 (+/- 0.0223)\n",
      "  balanced_accuracy: 0.1768 (+/- 0.0092)\n",
      "\n",
      "Naive Bayes:\n",
      "  accuracy: 0.3317 (+/- 0.0208)\n",
      "  recall_weighted: 0.3317 (+/- 0.0208)\n",
      "  precision_weighted: 0.3318 (+/- 0.0481)\n",
      "  f1_weighted: 0.2834 (+/- 0.0243)\n",
      "  f1_macro: 0.2123 (+/- 0.0198)\n",
      "  matthews: 0.2463 (+/- 0.0258)\n",
      "  balanced_accuracy: 0.2459 (+/- 0.0209)\n",
      "\n",
      "Gradient Boosting:\n",
      "  accuracy: 0.5789 (+/- 0.0285)\n",
      "  recall_weighted: 0.5789 (+/- 0.0285)\n",
      "  precision_weighted: 0.5960 (+/- 0.0346)\n",
      "  f1_weighted: 0.5713 (+/- 0.0289)\n",
      "  f1_macro: 0.5425 (+/- 0.0405)\n",
      "  matthews: 0.5218 (+/- 0.0325)\n",
      "  balanced_accuracy: 0.5240 (+/- 0.0398)\n",
      "\n",
      "Hist Gradient Boosting:\n",
      "  accuracy: 0.6439 (+/- 0.0179)\n",
      "  recall_weighted: 0.6439 (+/- 0.0179)\n",
      "  precision_weighted: 0.6500 (+/- 0.0162)\n",
      "  f1_weighted: 0.6425 (+/- 0.0177)\n",
      "  f1_macro: 0.6253 (+/- 0.0222)\n",
      "  matthews: 0.5965 (+/- 0.0200)\n",
      "  balanced_accuracy: 0.6118 (+/- 0.0234)\n",
      "\n",
      "XGBoost:\n",
      "  accuracy: 0.6634 (+/- 0.0104)\n",
      "  recall_weighted: 0.6634 (+/- 0.0104)\n",
      "  precision_weighted: 0.6713 (+/- 0.0135)\n",
      "  f1_weighted: 0.6630 (+/- 0.0112)\n",
      "  f1_macro: 0.6572 (+/- 0.0121)\n",
      "  matthews: 0.6187 (+/- 0.0116)\n",
      "  balanced_accuracy: 0.6436 (+/- 0.0097)\n",
      "\n",
      "LightGBM:\n",
      "  accuracy: 0.6268 (+/- 0.0214)\n",
      "  recall_weighted: 0.6268 (+/- 0.0214)\n",
      "  precision_weighted: 0.6378 (+/- 0.0190)\n",
      "  f1_weighted: 0.6244 (+/- 0.0191)\n",
      "  f1_macro: 0.6030 (+/- 0.0197)\n",
      "  matthews: 0.5772 (+/- 0.0237)\n",
      "  balanced_accuracy: 0.5892 (+/- 0.0228)\n",
      "\n",
      "CatBoost:\n",
      "  accuracy: 0.6049 (+/- 0.0107)\n",
      "  recall_weighted: 0.6049 (+/- 0.0107)\n",
      "  precision_weighted: 0.6155 (+/- 0.0101)\n",
      "  f1_weighted: 0.6002 (+/- 0.0118)\n",
      "  f1_macro: 0.5834 (+/- 0.0215)\n",
      "  matthews: 0.5514 (+/- 0.0122)\n",
      "  balanced_accuracy: 0.5679 (+/- 0.0195)\n",
      "\n",
      "Neural Network (MLP):\n",
      "  accuracy: 0.4211 (+/- 0.0203)\n",
      "  recall_weighted: 0.4211 (+/- 0.0203)\n",
      "  precision_weighted: 0.4186 (+/- 0.0265)\n",
      "  f1_weighted: 0.4162 (+/- 0.0216)\n",
      "  f1_macro: 0.3704 (+/- 0.0384)\n",
      "  matthews: 0.3441 (+/- 0.0238)\n",
      "  balanced_accuracy: 0.3737 (+/- 0.0421)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ESTRATEGIA 1:\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1: Utilizar todas las variables, codificando categóricas con dummies\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cat_cols1 = [\"exterior\", \"condition\", \"agency\", \"consumption_label\", \"emissions_label\"]\n",
    "\n",
    "X_zone_encoded_1 = pd.get_dummies(X_zone, columns=cat_cols1)\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_encoded_1.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_encoded_1.columns]\n",
    "y_zone_encoded_1 = LabelEncoder().fit_transform(y_zone)\n",
    "\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_encoded_1)}\")\n",
    "print(f\"Número de features: {X_zone_encoded_1.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_encoded_1)}\")\n",
    "\n",
    "result1 = evaluate_models(X_zone_encoded_1, y_zone_encoded_1, models=MODELS, cv_strategy=cv_strategy)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2acf1f9",
   "metadata": {},
   "source": [
    "### Strategy 1.1\n",
    "We have seen that some models handle categorical columns automatically (without having to use the dummies), which can improve both the time required to fit the model and the result, so we will try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a07500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1.1: Utilizar todas las variables, manteniendo categóricas como categorías (modelos que lo soportan)\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 17\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "XGBoost:\n",
      "  accuracy: 0.6285 (+/- 0.0211)\n",
      "  recall_weighted: 0.6285 (+/- 0.0211)\n",
      "  precision_weighted: 0.6354 (+/- 0.0232)\n",
      "  f1_weighted: 0.6253 (+/- 0.0221)\n",
      "  f1_macro: 0.6213 (+/- 0.0228)\n",
      "  matthews: 0.5792 (+/- 0.0242)\n",
      "  balanced_accuracy: 0.6127 (+/- 0.0271)\n",
      "\n",
      "LightGBM:\n",
      "  accuracy: 0.6699 (+/- 0.0151)\n",
      "  recall_weighted: 0.6699 (+/- 0.0151)\n",
      "  precision_weighted: 0.6793 (+/- 0.0130)\n",
      "  f1_weighted: 0.6680 (+/- 0.0145)\n",
      "  f1_macro: 0.6538 (+/- 0.0222)\n",
      "  matthews: 0.6260 (+/- 0.0169)\n",
      "  balanced_accuracy: 0.6401 (+/- 0.0238)\n",
      "\n",
      "CatBoost:\n",
      "  accuracy: 0.5764 (+/- 0.0181)\n",
      "  recall_weighted: 0.5764 (+/- 0.0181)\n",
      "  precision_weighted: 0.5914 (+/- 0.0205)\n",
      "  f1_weighted: 0.5667 (+/- 0.0183)\n",
      "  f1_macro: 0.5343 (+/- 0.0277)\n",
      "  matthews: 0.5199 (+/- 0.0206)\n",
      "  balanced_accuracy: 0.5221 (+/- 0.0267)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Models that handle categorical features natively\n",
    "MODELS_NATIVE = {\n",
    "    'XGBoost': XGBClassifier( n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1, tree_method=\"hist\", # <--- Necesario para el modo rápido\n",
    "        enable_categorical=True, use_label_encoder=False, eval_metric='mlogloss'), # <--- Habilita manejo de categóricas\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0, allow_writing_files=False,\n",
    "        cat_features=cat_cols1), # Evita crear carpetas 'catboost_info'\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1.1: Utilizar todas las variables, manteniendo categóricas como categorías (modelos que lo soportan)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_zone_unencoded_1 = X_zone.copy()\n",
    "\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_unencoded_1.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_uncoded_1.columns]\n",
    "y_zone_unencoded_1 = LabelEncoder().fit_transform(y_zone)\n",
    "\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_unencoded_1)}\")\n",
    "print(f\"Número de features: {X_zone_unencoded_1.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_unencoded_1)}\")\n",
    "\n",
    "result11 = evaluate_models(X_zone_unencoded_1, y_zone_unencoded_1, models=MODELS_NATIVE, scoring=SCORING)\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad92fb",
   "metadata": {},
   "source": [
    "### Strategy 1.2\n",
    "En la estrategia 1 no hemos podido usar SVM porque el tiempo de entrenamiento era demasiado largo, aun probando a ejecutarlo en la GPU en colab. Asi que vamos a reducir un poco la cantidad de dimensiones eliminando \"agency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acc1e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTRATEGIA 1.2: Utilizar svm\n",
      "================================================================================\n",
      "\n",
      "Número de muestras: 1230\n",
      "Número de features: 17\n",
      "Distribución de clases: [237 127  76  61  90 156 136  34 167  33 113]\n",
      "\n",
      "SVM (Linear):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[95]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNúmero de features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_zone_encoded_12.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDistribución de clases: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.bincount(y_zone_encoded_12)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result12 = \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_zone_encoded_12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_zone_encoded_12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODELS_SVM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSCORING\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mevaluate_models\u001b[39m\u001b[34m(X, y, cv_strategy, scoring, models)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     scores = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# We check the results with several metrics\u001b[39;00m\n\u001b[32m     10\u001b[39m     results[name] = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iker\\anaconda3\\envs\\machine_learning\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Models SVM\n",
    "MODELS_SVM = {\n",
    "    'SVM (Linear)': SVC(kernel='linear', random_state=42, probability=True),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ESTRATEGIA 1.2: Utilizar svm\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_zone_encoded_12 = X_zone.copy()\n",
    "X_zone_encoded_12[0:500]\n",
    "X_zone_encoded_12.drop(columns=[\"agency\", \"consumption_label\", \"emissions_label\"], inplace=True)  # Eliminamos \"agency\" para reducir dimensionalidad\n",
    "\n",
    "cat_cols12 = [\"exterior\", \"condition\"]\n",
    "X_zone_encoded_12 = pd.get_dummies(X_zone_encoded_12, columns=cat_cols12)\n",
    "# Eliminamos caracteres especiales de los nombres de las columnas que pueden hacer fallar algunos modelos\n",
    "X_zone_encoded_12.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_zone_encoded_12.columns]\n",
    "\n",
    "y_zone_encoded_12 = LabelEncoder().fit_transform(y_zone)\n",
    "print(f\"\\nNúmero de muestras: {len(X_zone_encoded_12)}\")\n",
    "print(f\"Número de features: {X_zone_encoded_12.shape[1]}\")\n",
    "print(f\"Distribución de clases: {np.bincount(y_zone_encoded_12)}\")\n",
    "\n",
    "result12 = evaluate_models(X_zone_encoded_12, y_zone_encoded_12, models=MODELS_SVM, scoring=SCORING)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
